{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">\n",
    "    <i>\n",
    "        LIN 537: Computational Lingusitics 1 <br>\n",
    "        Fall 2019 <br>\n",
    "        Alëna Aksënova\n",
    "    </i>\n",
    "</div>\n",
    "\n",
    "# Notebook 4: range, zip, enumerate, and useful string methods\n",
    "\n",
    "This notebook introduces a way to iterate over numbers within a certain range, therefore giving access to index-based iteration over containers using `range`. It also shows how to use `zip` and `enumerate`. Apart from it, it introduces several useful string methods such as `split` and `join`, and provides multiple practice exercises. Finally, it contains the implementation of $n$-gram extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For-loops: reminder\n",
    "\n",
    "_For-loops_ iterates over some object (**iterable**) and considers sub-elements of that object in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for letter in \"apple\":\n",
    "    print(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indicies = [0, 1, -1, -4]\n",
    "word = \"linguistics\"\n",
    "\n",
    "for index in indicies:\n",
    "    print(word[index], end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = [\"NYC\", \"LA\", \"SF\"]\n",
    "for city in cities:\n",
    "    print(\"The current city is\", city)\n",
    "    for ch in city:\n",
    "        print(\"\\t\", ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to print indicies of items in iterables, we can implement a **counter**, i.e. a variable that will increase every time some condition is met. In this case, we will set the counter to $0$ and increase it with every iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for letter in \"linguistics\":\n",
    "    print(letter, \"\\t index:\", index)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** Let's say we are given three lists: list of states (`states`), list of average temperatures for those states in the same order (`temperatures`) and a list of states that are considered New England (`new_england`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\"Alabama\",\"Alaska\",\"Arizona\",\"Arkansas\",\"California\",\"Colorado\",\n",
    "  \"Connecticut\",\"Delaware\",\"Florida\",\"Georgia\",\"Hawaii\",\"Idaho\",\"Illinois\",\n",
    "  \"Indiana\",\"Iowa\",\"Kansas\",\"Kentucky\",\"Louisiana\",\"Maine\",\"Maryland\",\n",
    "  \"Massachusetts\",\"Michigan\",\"Minnesota\",\"Mississippi\",\"Missouri\",\"Montana\",\n",
    "  \"Nebraska\",\"Nevada\",\"New Hampshire\",\"New Jersey\",\"New Mexico\",\"New York\",\n",
    "  \"North Carolina\",\"North Dakota\",\"Ohio\",\"Oklahoma\",\"Oregon\",\"Pennsylvania\",\n",
    "  \"Rhode Island\",\"South Carolina\",\"South Dakota\",\"Tennessee\",\"Texas\",\"Utah\",\n",
    "  \"Vermont\",\"Virginia\",\"Washington\",\"West Virginia\",\"Wisconsin\",\"Wyoming\"]\n",
    "\n",
    "temperatures = [62.8, 26.6, 60.3, 60.4, 59.4, 45.1, 49, 55.3, 70.7, 63.5,\n",
    "                70, 44.4, 51.8, 51.7, 47.8, 54.3, 55.6, 66.4, 41, 54.2, \n",
    "                47.9, 44.4, 41.2, 63.4, 54.5, 42.7, 48.8, 49.9, 43.8, 52.7, \n",
    "                53.4, 45.4, 59, 40.4, 50.7, 59.6, 48.4, 48.8, 50.1, 62.4, \n",
    "                45.2, 57.6, 64.8, 48.6, 42.9, 55.1, 48.3, 51.8, 43.1, 42]\n",
    "\n",
    "new_england = [\"Maine\", \"Vermont\", \"New Hampshire\", \"Massachusetts\", \"Connecticut\",\n",
    "               \"Rhode Island\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below prints average temperatures for New England states. The variable `index` stores the index of an item we are currently looking at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for state in states:\n",
    "    if state in new_england:\n",
    "        print(state+\":\", temperatures[index])\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice:** Helpful function for the following practice exercise is `sum` that takes list as an argument and returns the sum of all numbers in that list. FYI, functions `min` and `max` are available as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1, 18.3, 9, 0, 3.14]\n",
    "print(\"Sum of those numbers is\", sum(numbers))\n",
    "print(\"The smallest number is\", min(numbers))\n",
    "print(\"The largest number is\", max(numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the code above to print the average temperature in New England. (You can use the `round` function to make the resulting number prettier.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modifying strings\n",
    "\n",
    "String indecies cannot be reassigned, i.e. the existent parts of the string cannot be modified directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"hello\"\n",
    "string[-1] = \"a\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a task to \"mask\" all vowels from a text, we will need to create a new string based on the old one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vowels = \"aoiue\"\n",
    "text = \"This is a sentence that should contain no vowels.\"\n",
    "\n",
    "masked_text = \"\"\n",
    "for char in text:\n",
    "    if char not in vowels:\n",
    "        masked_text += char\n",
    "    else:\n",
    "        masked_text += \"*\"\n",
    "print(masked_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice:** You are given a string `alphabet` that contains all English letters, and a string `text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "text = \"A chessboard appeared, but it was triangular, and so big that only the nearest point could be seen.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code that makes this string lowercase and deletes punctuations from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Range\n",
    "\n",
    "**Range** is a numeric iterable defined by three arguments: _start_, _end_, and _step_. These arguments behave exactly as they do in slices: _start_ defines the initial numerical value, _end_ is the first value not included in the range, and _step_ defines the difference between the first and the following value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in range(1, 10):\n",
    "    print(value, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in range(1, 10, 2):\n",
    "    print(value, end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If only one argument is provided, it is considered to be _end_, and the initial value is assumed to be $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in range(10):\n",
    "    print(value, end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Range cannot be displayed directly, but can be easily converted to a list using `list` function.\n",
    "(If you are curious about the nature of the range object, read [this article](https://treyhunner.com/2018/02/python-range-is-not-an-iterator/), but a safe way is to just call it an iterable, or a range object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Printing range object:\", range(10))\n",
    "print(\"Typecasting range to a list:\", list(range(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to iteratively get indicies available in some iterable, we can use the following trick: `range(len(iterable))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"linguist\"\n",
    "for i in range(len(word)):\n",
    "    print(\"index:\", i, \"\\tsymbol:\", word[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N-grams\n",
    "\n",
    "$n$-grams are sequences of $n$ consequtive symbols.\n",
    "\n",
    "    word:   banana\n",
    "    n:      2\n",
    "    ngrams: ba, an, na\n",
    "    \n",
    "    word:   linguist\n",
    "    n:      3\n",
    "    ngrams: lin, ing, ngu, gui, uis, ist\n",
    "\n",
    "A special case of $n$-grams where the value of $n$ is $2$ are called _bigrams_. If $n=1$, these are called _unigrams_.\n",
    "\n",
    "For computational linguistics and NLP, **$n$-gram models** are extremely important: symbol-level $n$-gram models define which sequences of characters are (im)possible in a certain language, word-level $n$-gram models tell us which words can be adjacent to each other, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice:** write code that extracts _bigrams_ from a given word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enumerate and Zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object-defining functions that can sometimes be very useful are `enumerate` and `zip`.\n",
    "\n",
    "**`enumerate`** takes a list as input, and returns list of _tuples_, where every tuple contains an item from the input list, and its index. Just as `range`, this function creates its own object that can be easily typecasted into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = [\"NY\", \"CA\", \"RI\", \"CO\"]\n",
    "print(list(enumerate(input_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuple** is another basic data type in Python. While they share the majority of the functionality with lists, their main difference is that tuples cannot be modified as easily as lists. Tuples can be thought of as \"protected lists\", but read [here](https://realpython.com/python-lists-tuples/) to learn more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`zip`** takes arbitrary number of lists as input, and return a list of tuples, where every tuple is an index-wise combination of items from those lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "towns = [\"Port Jeff\", \"Stony Brook\", \"Lake Grove\"]\n",
    "zip_codes = [11777, 11790, 11755]\n",
    "print(list(zip(towns, zip_codes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Several useful string methods\n",
    "\n",
    "There are multiple methods that simplify working with strings and lists, and in this section, I exemplify the following ones: `replace`, `split`, `strip`, `join`, `startswith`, and `endswith`.\n",
    "\n",
    "**`replace`** returns a string in which some replacement was performed.\n",
    "\n",
    "    string.replace(old_substring, new_substring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"Hi friend. It is very nice to see you, friend!\"\n",
    "string = string.replace(\"friend\", \"Alex\")\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice:** Using the template provided below, greet everybody whose name is listed in the list `guests`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"Hi, [guest], it is very nice to meet you!\"\n",
    "guests = [\"Mary\", \"Jon\", \"Aniello\"]\n",
    "\n",
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`split`** takes a string and splits it into a list based on the provided argument. If no argument is provided, `split` splits the string based on the whitespaces.\n",
    "\n",
    "    string.split(separator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"A chessboard appeared, but it was triangular, and so big that only the nearest point could be seen.\"\n",
    "parsed_text = text.split()\n",
    "print(parsed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = \"Anna and Mary and John and Sebastian\"\n",
    "list_of_names = names.split(\" and \")\n",
    "print(list_of_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`strip`** removes inisible symbols from the ends of the string. The invisible things that `strip` removes are ` `, `\\n` and `\\t`. It is an extremely useful function when working with the \"dirty\" user input, or when processing text files.\n",
    "\n",
    "    string.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"\\nHello world!   \\t\"\n",
    "string = string.strip()\n",
    "print(\"-->\" + string + \"<--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`startswith`** and **`endswith`** are string methods that return booleans depending on the string starting or ending with a certain substring.\n",
    "\n",
    "    string.startswith(substring)\n",
    "    string.endswith(substring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"'hello' starts with 'hell':\", \"hello\".startswith(\"hell\"))\n",
    "print(\"'hello' starts with 'hi':\", \"hello\".startswith(\"hi\"))\n",
    "print(\"'hello' starts with 'hello':\", \"hello\".startswith(\"hello\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"'linguistics' ends with 'cs':\", \"linguistics\".endswith(\"cs\"))\n",
    "print(\"'linguistics' ends with '':\", \"linguistics\".endswith(\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`join`** is a string method that takes a list as argument, and, if all items within that list are strings, it concatenates them using the given string.\n",
    "\n",
    "    conjunction_string.join(list_to_concatenate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Anna', 'Mary', 'John', 'Sebastian']\n",
    "print(\" and \".join(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = ['P', 'y', 't', 'h', 'o', 'n']\n",
    "print(\"\".join(letters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4\n",
    "\n",
    "**Due on Thursday, October 3rd, 11.59pm**\n",
    "\n",
    "Send your notebook (don't forget to save your solutions!) to <alena.aksenova@stonybrook.edu> with the subject **\\[CompLing1\\] Homework 4**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1.** You are given the following list of English vowels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "vowels = [\"a\", \"o\", \"i\", \"u\", \"e\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the idea of a counter, implement code that ask user for a word, and then will print the number of consonants in that word. (For simplicity, we assume that \"y\" always behaves as a consonant, even though [it is not true](https://www.rd.com/culture/letter-y-vowel-consonant/).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: jazz\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "consonants = 0\n",
    "\n",
    "word = input(\"Word: \")\n",
    "for s in word:\n",
    "    if s not in vowels:\n",
    "        consonants += 1\n",
    "        \n",
    "print(consonants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2.**\n",
    "Implement code that asks the user for the value of $n$ and for a word, and extracts $n$-grams from that word for any $n$ provided by a user.\n",
    "\n",
    "    word:   banana\n",
    "    n:      2\n",
    "    ngrams: ba, an, na, an, na\n",
    "    \n",
    "    word:   linguist\n",
    "    n:      3\n",
    "    ngrams: lin, ing, ngu, gui, uis, ist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of n: 3\n",
      "Word: banana\n",
      "['ban', 'ana', 'nan']\n"
     ]
    }
   ],
   "source": [
    "n = int(input(\"Value of n: \"))\n",
    "word = input(\"Word: \")\n",
    "\n",
    "if len(word) < n:\n",
    "    print(\"The word is too short.\")\n",
    "    \n",
    "ngrams = []\n",
    "for i in range(len(word) - (n - 1)):\n",
    "    ngram = word[i:i+n]\n",
    "    if ngram not in ngrams:\n",
    "        ngrams.append(ngram)\n",
    "print(ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 3.** You are given the following text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"It was dark, like the bottom of a well. There was a pattern of skulls and bones around \\\n",
    "the frame, for the sake of appearances; Death could not look himself in the skull in a mirror \\\n",
    "with cherubs and roses around it. The Death of Rats climbed the frame in a scrabble of claws and \\\n",
    "looked at Death expectantly from the top. Quoth fluttered over and pecked briefly at his own \\\n",
    "reflection, on the basis that anything was worth a try. Show me, said Death, show me my thoughts. \\\n",
    "A chessboard appeared, but it was triangular, and so big that only the nearest point could be seen. \\\n",
    "Right on this point was the world - turtle, elephants, the little orbiting sun and all. It was the \\\n",
    "Discworld, which existed only just this side of total improbability and, therefore, in border country. \\\n",
    "In border country the border gets crossed, and sometimes things creep into the universe that have \\\n",
    "rather more on their mind than a better life for their children and a wonderful future in the \\\n",
    "fruit picking and domestic service industries. On every other black or white triangle of the \\\n",
    "chessboard, all the way to infinity, was a small grey shape, rather like an empty hooded robe.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are also given a string that contains all symbols of English alphabet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = \"abcdefghijklmnopqrstuvwxyz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Part 1._ Create a list `unique_words` with the unique lowercase words from `text`.\n",
    "\n",
    "You should see the following output (the order can differ!):\n",
    "    \n",
    "    ['a', 'infinity', 'reflection', 'with', 'like', 'big', 'briefly', 'into', 'children', 'which', 'fruit', 'picking', 'there', 'try', 'little', 'around', 'appearances', 'appeared', 'all', 'crossed', 'basis', 'improbability', 'their', 'discworld', 'black', 'to', 'death', 'future', 'only', 'my', 'robe', 'things', 'for', 'it', 'existed', 'said', 'sake', 'sometimes', 'right', 'way', 'that', 'country', 'chessboard', 'quoth', 'well', 'domestic', 'skull', 'wonderful', 'hooded', 'or', 'empty', 'bottom', 'mirror', 'himself', 'rather', 'over', 'every', 'triangle', 'roses', 'border', 'orbiting', 'was', 'from', 'show', 'be', 'pecked', 'bones', 'just', 'universe', 'me', 'triangular', 'gets', 'worth', 'have', 'climbed', 'service', 'fluttered', 'top', 'but', 'grey', 'claws', 'at', 'rats', 'creep', 'own', 'pattern', 'point', 'white', 'than', 'dark', 'therefore', 'frame', 'this', 'not', 'the', 'could', 'mind', 'turtle', 'scrabble', 'better', 'industries', 'looked', 'an', 'cherubs', 'life', 'anything', 'more', 'small', 'and', 'of', 'his', 'on', 'skulls', 'elephants', 'in', 'thoughts', 'seen', 'nearest', 'expectantly', 'other', 'side', 'shape', 'total', 'so', 'world', 'look', 'sun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'was', 'dark', 'like', 'the', 'bottom', 'of', 'a', 'well', 'there', 'pattern', 'skulls', 'and', 'bones', 'around', 'frame', 'for', 'sake', 'appearances', 'death', 'could', 'not', 'look', 'himself', 'in', 'skull', 'mirror', 'with', 'cherubs', 'roses', 'rats', 'climbed', 'scrabble', 'claws', 'looked', 'at', 'expectantly', 'from', 'top', 'quoth', 'fluttered', 'over', 'pecked', 'briefly', 'his', 'own', 'reflection', 'on', 'basis', 'that', 'anything', 'worth', 'try', 'show', 'me', 'said', 'my', 'thoughts', 'chessboard', 'appeared', 'but', 'triangular', 'so', 'big', 'only', 'nearest', 'point', 'be', 'seen', 'right', 'this', 'world', 'turtle', 'elephants', 'little', 'orbiting', 'sun', 'all', 'discworld', 'which', 'existed', 'just', 'side', 'total', 'improbability', 'therefore', 'border', 'country', 'gets', 'crossed', 'sometimes', 'things', 'creep', 'into', 'universe', 'have', 'rather', 'more', 'their', 'mind', 'than', 'better', 'life', 'children', 'wonderful', 'future', 'fruit', 'picking', 'domestic', 'service', 'industries', 'every', 'other', 'black', 'or', 'white', 'triangle', 'way', 'to', 'infinity', 'small', 'grey', 'shape', 'an', 'empty', 'hooded', 'robe']\n"
     ]
    }
   ],
   "source": [
    "new_text = \"\"\n",
    "for s in text.lower():\n",
    "    if s in alphabet + \" \":\n",
    "        new_text += s\n",
    "        \n",
    "#print(new_text)\n",
    "\n",
    "unique_words = []\n",
    "for w in text_split:\n",
    "    if w not in unique_words:\n",
    "        unique_words.append(w)\n",
    "\n",
    "#uq = [w for w in text_split if w not in uq]\n",
    "        \n",
    "print(unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Part 2._ Create a list `bigrams` in which you will collect all attested bigrams in `unique_words`. Ignore words that are shorter than $2$ characters. Make sure that the list `bigrams` does not contain duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'wa', 'as', 'da', 'ar', 'rk', 'li', 'ik', 'ke', 'th', 'he', 'bo', 'ot', 'tt', 'to', 'om', 'of', 'we', 'el', 'll', 'er', 're', 'pa', 'at', 'te', 'rn', 'sk', 'ku', 'ul', 'ls', 'an', 'nd', 'on', 'ne', 'es', 'ro', 'ou', 'un', 'fr', 'ra', 'am', 'me', 'fo', 'or', 'sa', 'ak', 'ap', 'pp', 'pe', 'ea', 'nc', 'ce', 'de', 'co', 'ld', 'no', 'lo', 'oo', 'ok', 'hi', 'im', 'ms', 'se', 'lf', 'in', 'mi', 'ir', 'rr', 'wi', 'ch', 'ru', 'ub', 'bs', 'os', 'ts', 'cl', 'mb', 'be', 'ed', 'sc', 'cr', 'ab', 'bb', 'bl', 'le', 'la', 'aw', 'ws', 'ex', 'xp', 'ec', 'ct', 'ta', 'nt', 'tl', 'ly', 'op', 'qu', 'uo', 'fl', 'lu', 'ut', 'ov', 've', 'ck', 'br', 'ri', 'ie', 'ef', 'is', 'ow', 'wn', 'ti', 'io', 'ba', 'si', 'ha', 'ny', 'yt', 'ng', 'wo', 'rt', 'tr', 'ry', 'sh', 'ho', 'ai', 'id', 'my', 'ug', 'gh', 'ht', 'ss', 'sb', 'oa', 'rd', 'bu', 'ia', 'gu', 'so', 'bi', 'ig', 'nl', 'st', 'po', 'oi', 'ee', 'en', 'rl', 'tu', 'ur', 'ep', 'ph', 'rb', 'su', 'al', 'di', 'cw', 'wh', 'ic', 'xi', 'ju', 'us', 'mp', 'pr', 'ob', 'il', 'ty', 'ge', 'et', 'gs', 'ni', 'iv', 'rs', 'av', 'mo', 'ei', 'if', 'fe', 'dr', 'rf', 'fu', 'ui', 'pi', 'ki', 'do', 'rv', 'vi', 'du', 'ev', 'ac', 'gl', 'ay', 'nf', 'fi', 'sm', 'ma', 'gr', 'ey', 'em', 'pt', 'od']\n"
     ]
    }
   ],
   "source": [
    "bigrams = []\n",
    "\n",
    "for w in unique_words:\n",
    "    if len(w) > 1:\n",
    "        \n",
    "        for i in range(len(w) - 1):\n",
    "            bigram = w[i:i+2]\n",
    "            if bigram not in bigrams:\n",
    "                bigrams.append(bigram)\n",
    "                \n",
    "print(bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Part 3._ Based on the `alphabet`, generate all possible bigrams of English. (Hint: look at the second exercise of the previous homework!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa', 'ab', 'ac', 'ad', 'ae', 'af', 'ag', 'ah', 'ai', 'aj', 'ak', 'al', 'am', 'an', 'ao', 'ap', 'aq', 'ar', 'as', 'at', 'au', 'av', 'aw', 'ax', 'ay', 'az', 'ba', 'bb', 'bc', 'bd', 'be', 'bf', 'bg', 'bh', 'bi', 'bj', 'bk', 'bl', 'bm', 'bn', 'bo', 'bp', 'bq', 'br', 'bs', 'bt', 'bu', 'bv', 'bw', 'bx', 'by', 'bz', 'ca', 'cb', 'cc', 'cd', 'ce', 'cf', 'cg', 'ch', 'ci', 'cj', 'ck', 'cl', 'cm', 'cn', 'co', 'cp', 'cq', 'cr', 'cs', 'ct', 'cu', 'cv', 'cw', 'cx', 'cy', 'cz', 'da', 'db', 'dc', 'dd', 'de', 'df', 'dg', 'dh', 'di', 'dj', 'dk', 'dl', 'dm', 'dn', 'do', 'dp', 'dq', 'dr', 'ds', 'dt', 'du', 'dv', 'dw', 'dx', 'dy', 'dz', 'ea', 'eb', 'ec', 'ed', 'ee', 'ef', 'eg', 'eh', 'ei', 'ej', 'ek', 'el', 'em', 'en', 'eo', 'ep', 'eq', 'er', 'es', 'et', 'eu', 'ev', 'ew', 'ex', 'ey', 'ez', 'fa', 'fb', 'fc', 'fd', 'fe', 'ff', 'fg', 'fh', 'fi', 'fj', 'fk', 'fl', 'fm', 'fn', 'fo', 'fp', 'fq', 'fr', 'fs', 'ft', 'fu', 'fv', 'fw', 'fx', 'fy', 'fz', 'ga', 'gb', 'gc', 'gd', 'ge', 'gf', 'gg', 'gh', 'gi', 'gj', 'gk', 'gl', 'gm', 'gn', 'go', 'gp', 'gq', 'gr', 'gs', 'gt', 'gu', 'gv', 'gw', 'gx', 'gy', 'gz', 'ha', 'hb', 'hc', 'hd', 'he', 'hf', 'hg', 'hh', 'hi', 'hj', 'hk', 'hl', 'hm', 'hn', 'ho', 'hp', 'hq', 'hr', 'hs', 'ht', 'hu', 'hv', 'hw', 'hx', 'hy', 'hz', 'ia', 'ib', 'ic', 'id', 'ie', 'if', 'ig', 'ih', 'ii', 'ij', 'ik', 'il', 'im', 'in', 'io', 'ip', 'iq', 'ir', 'is', 'it', 'iu', 'iv', 'iw', 'ix', 'iy', 'iz', 'ja', 'jb', 'jc', 'jd', 'je', 'jf', 'jg', 'jh', 'ji', 'jj', 'jk', 'jl', 'jm', 'jn', 'jo', 'jp', 'jq', 'jr', 'js', 'jt', 'ju', 'jv', 'jw', 'jx', 'jy', 'jz', 'ka', 'kb', 'kc', 'kd', 'ke', 'kf', 'kg', 'kh', 'ki', 'kj', 'kk', 'kl', 'km', 'kn', 'ko', 'kp', 'kq', 'kr', 'ks', 'kt', 'ku', 'kv', 'kw', 'kx', 'ky', 'kz', 'la', 'lb', 'lc', 'ld', 'le', 'lf', 'lg', 'lh', 'li', 'lj', 'lk', 'll', 'lm', 'ln', 'lo', 'lp', 'lq', 'lr', 'ls', 'lt', 'lu', 'lv', 'lw', 'lx', 'ly', 'lz', 'ma', 'mb', 'mc', 'md', 'me', 'mf', 'mg', 'mh', 'mi', 'mj', 'mk', 'ml', 'mm', 'mn', 'mo', 'mp', 'mq', 'mr', 'ms', 'mt', 'mu', 'mv', 'mw', 'mx', 'my', 'mz', 'na', 'nb', 'nc', 'nd', 'ne', 'nf', 'ng', 'nh', 'ni', 'nj', 'nk', 'nl', 'nm', 'nn', 'no', 'np', 'nq', 'nr', 'ns', 'nt', 'nu', 'nv', 'nw', 'nx', 'ny', 'nz', 'oa', 'ob', 'oc', 'od', 'oe', 'of', 'og', 'oh', 'oi', 'oj', 'ok', 'ol', 'om', 'on', 'oo', 'op', 'oq', 'or', 'os', 'ot', 'ou', 'ov', 'ow', 'ox', 'oy', 'oz', 'pa', 'pb', 'pc', 'pd', 'pe', 'pf', 'pg', 'ph', 'pi', 'pj', 'pk', 'pl', 'pm', 'pn', 'po', 'pp', 'pq', 'pr', 'ps', 'pt', 'pu', 'pv', 'pw', 'px', 'py', 'pz', 'qa', 'qb', 'qc', 'qd', 'qe', 'qf', 'qg', 'qh', 'qi', 'qj', 'qk', 'ql', 'qm', 'qn', 'qo', 'qp', 'qq', 'qr', 'qs', 'qt', 'qu', 'qv', 'qw', 'qx', 'qy', 'qz', 'ra', 'rb', 'rc', 'rd', 're', 'rf', 'rg', 'rh', 'ri', 'rj', 'rk', 'rl', 'rm', 'rn', 'ro', 'rp', 'rq', 'rr', 'rs', 'rt', 'ru', 'rv', 'rw', 'rx', 'ry', 'rz', 'sa', 'sb', 'sc', 'sd', 'se', 'sf', 'sg', 'sh', 'si', 'sj', 'sk', 'sl', 'sm', 'sn', 'so', 'sp', 'sq', 'sr', 'ss', 'st', 'su', 'sv', 'sw', 'sx', 'sy', 'sz', 'ta', 'tb', 'tc', 'td', 'te', 'tf', 'tg', 'th', 'ti', 'tj', 'tk', 'tl', 'tm', 'tn', 'to', 'tp', 'tq', 'tr', 'ts', 'tt', 'tu', 'tv', 'tw', 'tx', 'ty', 'tz', 'ua', 'ub', 'uc', 'ud', 'ue', 'uf', 'ug', 'uh', 'ui', 'uj', 'uk', 'ul', 'um', 'un', 'uo', 'up', 'uq', 'ur', 'us', 'ut', 'uu', 'uv', 'uw', 'ux', 'uy', 'uz', 'va', 'vb', 'vc', 'vd', 've', 'vf', 'vg', 'vh', 'vi', 'vj', 'vk', 'vl', 'vm', 'vn', 'vo', 'vp', 'vq', 'vr', 'vs', 'vt', 'vu', 'vv', 'vw', 'vx', 'vy', 'vz', 'wa', 'wb', 'wc', 'wd', 'we', 'wf', 'wg', 'wh', 'wi', 'wj', 'wk', 'wl', 'wm', 'wn', 'wo', 'wp', 'wq', 'wr', 'ws', 'wt', 'wu', 'wv', 'ww', 'wx', 'wy', 'wz', 'xa', 'xb', 'xc', 'xd', 'xe', 'xf', 'xg', 'xh', 'xi', 'xj', 'xk', 'xl', 'xm', 'xn', 'xo', 'xp', 'xq', 'xr', 'xs', 'xt', 'xu', 'xv', 'xw', 'xx', 'xy', 'xz', 'ya', 'yb', 'yc', 'yd', 'ye', 'yf', 'yg', 'yh', 'yi', 'yj', 'yk', 'yl', 'ym', 'yn', 'yo', 'yp', 'yq', 'yr', 'ys', 'yt', 'yu', 'yv', 'yw', 'yx', 'yy', 'yz', 'za', 'zb', 'zc', 'zd', 'ze', 'zf', 'zg', 'zh', 'zi', 'zj', 'zk', 'zl', 'zm', 'zn', 'zo', 'zp', 'zq', 'zr', 'zs', 'zt', 'zu', 'zv', 'zw', 'zx', 'zy', 'zz']\n"
     ]
    }
   ],
   "source": [
    "alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "possible_bigrams = []\n",
    "\n",
    "for s in alphabet:\n",
    "    for a in alphabet:\n",
    "        bigram = s+a\n",
    "        if bigram not in possible_bigrams:\n",
    "            possible_bigrams.append(bigram)\n",
    "\n",
    "print(possible_bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Part 4._ Collect all unattested bigrams of English in the list `unattested_bigrams`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa', 'ad', 'ae', 'af', 'ag', 'ah', 'aj', 'ao', 'aq', 'au', 'ax', 'az', 'bc', 'bd', 'bf', 'bg', 'bh', 'bj', 'bk', 'bm', 'bn', 'bp', 'bq', 'bt', 'bv', 'bw', 'bx', 'by', 'bz', 'ca', 'cb', 'cc', 'cd', 'cf', 'cg', 'ci', 'cj', 'cm', 'cn', 'cp', 'cq', 'cs', 'cu', 'cv', 'cx', 'cy', 'cz', 'db', 'dc', 'dd', 'df', 'dg', 'dh', 'dj', 'dk', 'dl', 'dm', 'dn', 'dp', 'dq', 'ds', 'dt', 'dv', 'dw', 'dx', 'dy', 'dz', 'eb', 'eg', 'eh', 'ej', 'ek', 'eo', 'eq', 'eu', 'ew', 'ez', 'fa', 'fb', 'fc', 'fd', 'ff', 'fg', 'fh', 'fj', 'fk', 'fm', 'fn', 'fp', 'fq', 'fs', 'ft', 'fv', 'fw', 'fx', 'fy', 'fz', 'ga', 'gb', 'gc', 'gd', 'gf', 'gg', 'gi', 'gj', 'gk', 'gm', 'gn', 'go', 'gp', 'gq', 'gt', 'gv', 'gw', 'gx', 'gy', 'gz', 'hb', 'hc', 'hd', 'hf', 'hg', 'hh', 'hj', 'hk', 'hl', 'hm', 'hn', 'hp', 'hq', 'hr', 'hs', 'hu', 'hv', 'hw', 'hx', 'hy', 'hz', 'ib', 'ih', 'ii', 'ij', 'ip', 'iq', 'iu', 'iw', 'ix', 'iy', 'iz', 'ja', 'jb', 'jc', 'jd', 'je', 'jf', 'jg', 'jh', 'ji', 'jj', 'jk', 'jl', 'jm', 'jn', 'jo', 'jp', 'jq', 'jr', 'js', 'jt', 'jv', 'jw', 'jx', 'jy', 'jz', 'ka', 'kb', 'kc', 'kd', 'kf', 'kg', 'kh', 'kj', 'kk', 'kl', 'km', 'kn', 'ko', 'kp', 'kq', 'kr', 'ks', 'kt', 'kv', 'kw', 'kx', 'ky', 'kz', 'lb', 'lc', 'lg', 'lh', 'lj', 'lk', 'lm', 'ln', 'lp', 'lq', 'lr', 'lt', 'lv', 'lw', 'lx', 'lz', 'mc', 'md', 'mf', 'mg', 'mh', 'mj', 'mk', 'ml', 'mm', 'mn', 'mq', 'mr', 'mt', 'mu', 'mv', 'mw', 'mx', 'mz', 'na', 'nb', 'nh', 'nj', 'nk', 'nm', 'nn', 'np', 'nq', 'nr', 'ns', 'nu', 'nv', 'nw', 'nx', 'nz', 'oc', 'oe', 'og', 'oh', 'oj', 'ol', 'oq', 'ox', 'oy', 'oz', 'pb', 'pc', 'pd', 'pf', 'pg', 'pj', 'pk', 'pl', 'pm', 'pn', 'pq', 'ps', 'pu', 'pv', 'pw', 'px', 'py', 'pz', 'qa', 'qb', 'qc', 'qd', 'qe', 'qf', 'qg', 'qh', 'qi', 'qj', 'qk', 'ql', 'qm', 'qn', 'qo', 'qp', 'qq', 'qr', 'qs', 'qt', 'qv', 'qw', 'qx', 'qy', 'qz', 'rc', 'rg', 'rh', 'rj', 'rm', 'rp', 'rq', 'rw', 'rx', 'rz', 'sd', 'sf', 'sg', 'sj', 'sl', 'sn', 'sp', 'sq', 'sr', 'sv', 'sw', 'sx', 'sy', 'sz', 'tb', 'tc', 'td', 'tf', 'tg', 'tj', 'tk', 'tm', 'tn', 'tp', 'tq', 'tv', 'tw', 'tx', 'tz', 'ua', 'uc', 'ud', 'ue', 'uf', 'uh', 'uj', 'uk', 'um', 'up', 'uq', 'uu', 'uv', 'uw', 'ux', 'uy', 'uz', 'va', 'vb', 'vc', 'vd', 'vf', 'vg', 'vh', 'vj', 'vk', 'vl', 'vm', 'vn', 'vo', 'vp', 'vq', 'vr', 'vs', 'vt', 'vu', 'vv', 'vw', 'vx', 'vy', 'vz', 'wb', 'wc', 'wd', 'wf', 'wg', 'wj', 'wk', 'wl', 'wm', 'wp', 'wq', 'wr', 'wt', 'wu', 'wv', 'ww', 'wx', 'wy', 'wz', 'xa', 'xb', 'xc', 'xd', 'xe', 'xf', 'xg', 'xh', 'xj', 'xk', 'xl', 'xm', 'xn', 'xo', 'xq', 'xr', 'xs', 'xt', 'xu', 'xv', 'xw', 'xx', 'xy', 'xz', 'ya', 'yb', 'yc', 'yd', 'ye', 'yf', 'yg', 'yh', 'yi', 'yj', 'yk', 'yl', 'ym', 'yn', 'yo', 'yp', 'yq', 'yr', 'ys', 'yu', 'yv', 'yw', 'yx', 'yy', 'yz', 'za', 'zb', 'zc', 'zd', 'ze', 'zf', 'zg', 'zh', 'zi', 'zj', 'zk', 'zl', 'zm', 'zn', 'zo', 'zp', 'zq', 'zr', 'zs', 'zt', 'zu', 'zv', 'zw', 'zx', 'zy', 'zz']\n"
     ]
    }
   ],
   "source": [
    "unattested_bigrams = [b for b in possible_bigrams if b not in bigrams]\n",
    "print(unattested_bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't be surprised that some bigrams from `unattested_bigrams` are actually present in other English words, the text that we are working with is very small! If you are curious, take a larger text, and run your code on it. :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
